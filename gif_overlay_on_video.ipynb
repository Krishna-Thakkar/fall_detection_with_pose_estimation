{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Function to overlay GIF on video\n",
    "# def overlay_gif_on_video(video_path, gif_path, output_path):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     gif = cv2.VideoCapture(gif_path)\n",
    "\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "#     while True:\n",
    "#         ret_video, frame = cap.read()\n",
    "#         # if not ret:\n",
    "#         #     break\n",
    "\n",
    "#         ret_gif, gif_frame = gif.read()\n",
    "#         # if not ret_video or not ret_gif:\n",
    "#         #     break\n",
    "#         # if not ret_video:\n",
    "#         #     gif.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset GIF to the beginning\n",
    "\n",
    "#         if not ret_video:\n",
    "#             break\n",
    "\n",
    "#         if not ret_gif:\n",
    "#             gif.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "#             continue\n",
    "\n",
    "#         # Resize the gif_frame to fit the video frame\n",
    "#         gif_frame = cv2.resize(gif_frame, (width, height))\n",
    "\n",
    "#         # Blend the video frame and gif_frame\n",
    "#         blended_frame = cv2.addWeighted(frame, 1, gif_frame, 0.5, 0)\n",
    "\n",
    "#         out.write(blended_frame)\n",
    "\n",
    "#     cap.release()\n",
    "#     gif.release()\n",
    "#     out.release()\n",
    "\n",
    "# # Paths to the input video, input GIF, and output video\n",
    "# video_path = '/home/mind/projects/projects/pose_estimation/videos/N1IQOkcGESotWAcMVBIUOy5GQiFbDgtqYmMmEn8wMRcccisbdVlHaGEETGA.mp4'\n",
    "# gif_path = '/home/mind/projects/projects/pose_estimation/videos/warning.gif'\n",
    "# output_video_path = '/home/mind/projects/projects/pose_estimation/videos/output-overlay.mp4'\n",
    "\n",
    "# # Overlay the GIF on the video and save the output\n",
    "# overlay_gif_on_video(video_path, gif_path, output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to overlay GIF on a specific region of the video\n",
    "def overlay_gif_on_video(video_path, gif_path, output_path, gif_position):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    gif = cv2.VideoCapture(gif_path)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    gif_width = 300  # Width of the region for the GIF\n",
    "    gif_height = 100  # Height of the region for the GIF\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while True:\n",
    "        ret_video, frame = cap.read()\n",
    "        ret_gif, gif_frame = gif.read()\n",
    "\n",
    "        if not ret_video:\n",
    "            break\n",
    "\n",
    "        if not ret_gif:\n",
    "            gif.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            continue\n",
    "\n",
    "        # Resize the gif_frame to fit the specified region\n",
    "        gif_frame = cv2.resize(gif_frame, (gif_width, gif_height))\n",
    "\n",
    "        # Define the region of interest (ROI)\n",
    "        roi = frame[gif_position[1]:gif_position[1] + gif_height, gif_position[0]:gif_position[0] + gif_width]\n",
    "\n",
    "        # Blend the video frame and gif_frame using numpy\n",
    "        blended_frame = cv2.addWeighted(roi, 0, gif_frame, 1, 0)\n",
    "\n",
    "        # Replace the original ROI with the blended_frame\n",
    "        frame[gif_position[1]:gif_position[1] + gif_height, gif_position[0]:gif_position[0] + gif_width] = blended_frame\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    gif.release()\n",
    "    out.release()\n",
    "\n",
    "# Paths to the input video, input GIF, and output video\n",
    "video_path = '/home/mind/projects/projects/pose_estimation/videos/N1IQOkcGESotWAcMVBIUOy5GQiFbDgtqYmMmEn8wMRcccisbdVlHaGEETGA.mp4'\n",
    "gif_path = '/home/mind/projects/projects/pose_estimation/videos/warning.gif'\n",
    "output_video_path = '/home/mind/projects/projects/pose_estimation/output-overlay.mp4'\n",
    "\n",
    "# Position of the GIF on the video\n",
    "gif_position = (475, 90)\n",
    "\n",
    "# Overlay the GIF on the specified region of the video and save the output\n",
    "overlay_gif_on_video(video_path, gif_path, output_video_path, gif_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to overlay GIF on a specific region of the video\n",
    "def overlay_gif_on_video(video_path, gif_path, output_path, gif_position):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    gif = cv2.VideoCapture(gif_path)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    gif_width = 300  # Width of the region for the GIF\n",
    "    gif_height = 100  # Height of the region for the GIF\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    smoothing_factor = 0  # Adjust the smoothing factor\n",
    "\n",
    "    previous_gif_frame = None\n",
    "\n",
    "    while True:\n",
    "        ret_video, frame = cap.read()\n",
    "        ret_gif, gif_frame = gif.read()\n",
    "\n",
    "        if not ret_video:\n",
    "            break\n",
    "\n",
    "        if not ret_gif:\n",
    "            gif.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            continue\n",
    "\n",
    "        # Resize the gif_frame to fit the specified region\n",
    "        gif_frame = cv2.resize(gif_frame, (gif_width, gif_height))\n",
    "\n",
    "        # Apply smoothing to the gif_frame\n",
    "        if previous_gif_frame is not None:\n",
    "            gif_frame = cv2.addWeighted(previous_gif_frame, 1 - smoothing_factor, gif_frame, smoothing_factor, 0)\n",
    "\n",
    "        previous_gif_frame = gif_frame.copy()\n",
    "\n",
    "        # Define the region of interest (ROI)\n",
    "        roi = frame[gif_position[1]:gif_position[1] + gif_height, gif_position[0]:gif_position[0] + gif_width]\n",
    "\n",
    "        # Blend the video frame and gif_frame using numpy\n",
    "        blended_frame = cv2.addWeighted(roi, 0, gif_frame, 1, 0)\n",
    "\n",
    "        # Replace the original ROI with the blended_frame\n",
    "        frame[gif_position[1]:gif_position[1] + gif_height, gif_position[0]:gif_position[0] + gif_width] = blended_frame\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    gif.release()\n",
    "    out.release()\n",
    "\n",
    "# Paths to the input video, input GIF, and output video\n",
    "video_path = '/home/mind/projects/projects/pose_estimation/videos/N1IQOkcGESotWAcMVBIUOy5GQiFbDgtqYmMmEn8wMRcccisbdVlHaGEETGA.mp4'\n",
    "gif_path = '/home/mind/projects/projects/pose_estimation/videos/warning.gif'\n",
    "output_video_path = '/home/mind/projects/projects/pose_estimation/output-overlay.mp4'\n",
    "\n",
    "# Position of the GIF on the video (top-left corner in this example)\n",
    "gif_position = (475, 90)\n",
    "\n",
    "# Overlay the GIF on the specified region of the video with temporal smoothing and save the output\n",
    "overlay_gif_on_video(video_path, gif_path, output_video_path, gif_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 30 is out of bounds for axis 1 with size 30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m roi \u001b[38;5;241m=\u001b[39m frame[\u001b[38;5;241m420\u001b[39m:\u001b[38;5;241m633\u001b[39m, \u001b[38;5;241m75\u001b[39m:\u001b[38;5;241m105\u001b[39m]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Set an index of where the mask is \u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mroi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     32\u001b[0m roi \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m img \n\u001b[1;32m     34\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m, frame) \n",
      "\u001b[0;31mIndexError\u001b[0m: index 30 is out of bounds for axis 1 with size 30"
     ]
    }
   ],
   "source": [
    "# importing the libraries \n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "# Setup camera \n",
    "cap = cv2.VideoCapture('/home/mind/projects/projects/pose_estimation/videos/N1IQOkcGESotWAcMVBIUOy5GQiFbDgtqYmMmEn8wMRcccisbdVlHaGEETGA.mp4') \n",
    "\n",
    "# Read img and resize \n",
    "img = cv2.imread('/home/mind/projects/projects/pose_estimation/warning.jpg') \n",
    "size = 100\n",
    "img = cv2.resize(img, (size, size)) \n",
    "\n",
    "# Create a mask of img \n",
    "img2gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "ret, mask = cv2.threshold(img2gray, 1, 255, cv2.THRESH_BINARY) \n",
    "\n",
    "img_position = (475, 90)\n",
    "img_width = 300  \n",
    "img_height = 100\n",
    "\n",
    "while cap.isOpened(): \n",
    "\t# Capture frame-by-frame \n",
    "\tret, frame = cap.read() \n",
    "\n",
    "\tif ret:\n",
    "\t\t# Region of Image (ROI), where we want to insert img \n",
    "\t\t# roi = frame[-size-10:-10, -size-10:-10]\n",
    "\t\troi = frame[420:633, 75:105]\n",
    "\t\t\n",
    "\t\t# Set an index of where the mask is \n",
    "\t\troi[np.where(mask)] = 0\n",
    "\t\troi += img \n",
    "\n",
    "\t\tcv2.imshow('video', frame) \n",
    "\t\tif cv2.waitKey(1) == ord('q'): \n",
    "\t\t\tbreak\n",
    "\telse:\n",
    "\t\tbreak\n",
    "\n",
    "# When everything done, release the capture \n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    " \n",
    "# Setup camera \n",
    "cap = cv2.VideoCapture('/home/mind/projects/projects/pose_estimation/videos/N1IQOkcGESotWAcMVBIUOy5GQiFbDgtqYmMmEn8wMRcccisbdVlHaGEETGA.mp4') \n",
    "\n",
    "# Read img and resize \n",
    "img = cv2.imread('/home/mind/projects/projects/pose_estimation/warning.jpg') \n",
    "new_image = cv2.resize(img, (250, 100))\n",
    "\n",
    "fps = int(cap.get(5))\n",
    "frame_count = 0\n",
    "# print(fps)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # read the background\n",
    "    ret, background = cap.read()\n",
    "    if ret:\n",
    "        frame_count += 1\n",
    "        if frame_count <= fps//2:\n",
    "            background[50:150, 475:725] = cv2.addWeighted(background[50:150, 475:725], 0, new_image, 1, 0)\n",
    "        else:\n",
    "            background[50:150, 475:725] = cv2.addWeighted(background[50:150, 475:725], 1, new_image, 0, 0)\n",
    "        if frame_count == 30:\n",
    "            frame_count = 0\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.imshow('a',background)\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == ord('q'):\n",
    "            break      \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose_estimation_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
